import os
import sys
import requests
import json
import gradio as gr
import logging
from typing import List, Optional, Dict, Tuple, Any
from dataclasses import dataclass
from dotenv import load_dotenv
import base64
import threading
import time
from logging.handlers import RotatingFileHandler
import functools
from PIL import Image
import io
from urllib.parse import urlparse
import tempfile

# Load environment variables
load_dotenv()

# Configure logging with rotation
def setup_logging():
    log_file = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'chatbot.log')
    handler = RotatingFileHandler(
        log_file,
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5,
        encoding='utf-8'
    )
    handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
    
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)
    logger.addHandler(handler)
    
    # Also log to console
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(logging.Formatter('%(levelname)s: %(message)s'))
    logger.addHandler(console_handler)
    
    return logger

logger = setup_logging()

# Configuration
class Config:
    # Default values as class attributes
    API_BASE_URL = os.getenv('OLLAMA_API_URL', 'http://localhost:11434')
    GRADIO_SERVER_PORT = int(os.getenv('GRADIO_SERVER_PORT', '7588'))
    OCR_TIMEOUT = int(os.getenv('OCR_TIMEOUT', '60'))
    CHAT_TIMEOUT = int(os.getenv('CHAT_TIMEOUT', '30'))
    MAX_HISTORY = int(os.getenv('MAX_HISTORY', '100'))
    RETRY_ATTEMPTS = int(os.getenv('RETRY_ATTEMPTS', '3'))
    REQUEST_RATE_LIMIT = int(os.getenv('REQUEST_RATE_LIMIT', '10'))
    CACHE_TIMEOUT = int(os.getenv('CACHE_TIMEOUT', '3600'))
    MAX_INPUT_LENGTH = int(os.getenv('MAX_INPUT_LENGTH', '1000'))

    API_GENERATE_URL = f"{API_BASE_URL}/api/generate"
    API_CHAT_URL = f"{API_BASE_URL}/api/chat"

    @classmethod
    def validate(cls):
        if not (1024 <= cls.GRADIO_SERVER_PORT <= 65535):
            raise ValueError("Port must be between 1024 and 65535")
        if cls.OCR_TIMEOUT < 5:
            logger.warning(f"OCR_TIMEOUT is too small, using 5s")
            cls.OCR_TIMEOUT = 5
        if cls.CHAT_TIMEOUT < 5:
            logger.warning(f"CHAT_TIMEOUT is too small, using 5s")
            cls.CHAT_TIMEOUT = 5
        try:
            result = urlparse(cls.API_BASE_URL)
            if not all([result.scheme, result.netloc]):
                raise ValueError("Invalid URL format")
        except Exception as e:
            raise ValueError(f"Invalid API URL configuration: {str(e)}")

# Validate configuration on module load
Config.validate()

class RateLimit:
    def __init__(self, max_requests: int, per_seconds: int = 60):
        self.max_requests = max_requests
        self.per_seconds = per_seconds
        self.requests = []
        self._lock = threading.Lock()

    def is_allowed(self) -> bool:
        now = time.time()
        with self._lock:
            # æ¸…ç†è¿‡æœŸçš„è¯·æ±‚è®°å½•
            self.requests = [req_time for req_time in self.requests 
                           if now - req_time < self.per_seconds]
            
            if len(self.requests) >= self.max_requests:
                return False
                
            self.requests.append(now)
            return True

class Cache:
    def __init__(self, timeout: int = 3600):
        self.cache = {}
        self.timeout = timeout
        self._lock = threading.Lock()

    def get(self, key: str) -> Optional[str]:
        with self._lock:
            if key in self.cache:
                timestamp, value = self.cache[key]
                if time.time() - timestamp < self.timeout:
                    return value
                del self.cache[key]
            return None

    def set(self, key: str, value: str) -> None:
        with self._lock:
            self.cache[key] = (time.time(), value)

class Conversation:
    def __init__(self, history: List[str], max_length: int = Config.MAX_HISTORY):
        self.history = history
        self.max_length = max_length

    def add_message(self, message: str) -> None:
        self.history.append(message)
        if len(self.history) > self.max_length:
            self.history = self.history[-self.max_length:]

    def get_context(self) -> str:
        return "\n".join(self.history)

    def clear(self) -> None:
        self.history = []

class ResourceManager:
    def __init__(self, base_dir: str = None):
        if base_dir is None:
            base_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'temp')
        self.base_dir = base_dir
        self.temp_files = set()
        self._lock = threading.Lock()
        self._setup_temp_dir()
        
    def _setup_temp_dir(self):
        """åˆå§‹åŒ–ä¸´æ—¶ç›®å½•"""
        try:
            os.makedirs(self.base_dir, exist_ok=True)
            # å¯åŠ¨æ—¶æ¸…ç†é—ç•™çš„ä¸´æ—¶æ–‡ä»¶
            self.cleanup_all()
        except Exception as e:
            logger.error(f"Failed to setup temp directory: {e}")
            raise
            
    def add_temp_file(self, filepath: str):
        """è®°å½•ä¸´æ—¶æ–‡ä»¶"""
        with self._lock:
            self.temp_files.add(filepath)
            
    def remove_temp_file(self, filepath: str):
        """åˆ é™¤ä¸´æ—¶æ–‡ä»¶"""
        with self._lock:
            try:
                if os.path.exists(filepath):
                    os.remove(filepath)
                self.temp_files.discard(filepath)
            except Exception as e:
                logger.error(f"Failed to remove temp file {filepath}: {e}")
                
    def cleanup_all(self):
        """æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶"""
        with self._lock:
            for filepath in list(self.temp_files):
                self.remove_temp_file(filepath)
            # æ¸…ç†å¯èƒ½é—ç•™çš„å…¶ä»–ä¸´æ—¶æ–‡ä»¶
            for filename in os.listdir(self.base_dir):
                try:
                    filepath = os.path.join(self.base_dir, filename)
                    if os.path.isfile(filepath):
                        os.remove(filepath)
                except Exception as e:
                    logger.error(f"Failed to remove file {filepath}: {e}")
                    
    def create_temp_file(self, suffix: str = '') -> str:
        """åˆ›å»ºä¸´æ—¶æ–‡ä»¶"""
        with self._lock:
            try:
                fd, temp_path = tempfile.mkstemp(suffix=suffix, dir=self.base_dir)
                os.close(fd)
                self.add_temp_file(temp_path)
                return temp_path
            except Exception as e:
                logger.error(f"Failed to create temp file: {e}")
                raise
                
    def __del__(self):
        """ç¡®ä¿åœ¨å¯¹è±¡é”€æ¯æ—¶æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        self.cleanup_all()

class ProcessState:
    """å¤„ç†çŠ¶æ€ç®¡ç†"""
    def __init__(self):
        self._state = {}
        self._lock = threading.Lock()
        
    def set_state(self, key: str, value: Any) -> None:
        """è®¾ç½®çŠ¶æ€"""
        with self._lock:
            self._state[key] = value
            
    def get_state(self, key: str, default: Any = None) -> Any:
        """è·å–çŠ¶æ€"""
        with self._lock:
            return self._state.get(key, default)
            
    def clear_state(self, key: str) -> None:
        """æ¸…é™¤çŠ¶æ€"""
        with self._lock:
            self._state.pop(key, None)
            
    def is_processing(self, key: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ­£åœ¨å¤„ç†"""
        return self.get_state(key) == 'processing'

def retry_on_exception(retries: int = 3, delay: float = 1.0):
    """é‡è¯•è£…é¥°å™¨"""
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == retries - 1:
                        raise
                    logger.warning(f"Attempt {attempt + 1} failed: {e}")
                    time.sleep(delay * (attempt + 1))  # æŒ‡æ•°é€€é¿
            return None
        return wrapper
    return decorator

class ChatBot:
    def __init__(self):
        self.conversation = Conversation([])
        self.session = requests.Session()
        self.current_image: Optional[str] = None
        self.current_ocr_result: Optional[str] = None
        self.rate_limit = RateLimit(Config.REQUEST_RATE_LIMIT)
        self.cache = Cache(Config.CACHE_TIMEOUT)
        self.resource_manager = ResourceManager()
        self.process_state = ProcessState()
        
        # è®¾ç½®ä¼šè¯è¶…æ—¶
        self.session.timeout = (Config.CHAT_TIMEOUT, Config.CHAT_TIMEOUT)
        
        # è®¾ç½®é‡è¯•ç­–ç•¥
        retry_strategy = requests.adapters.Retry(
            total=3,
            backoff_factor=0.5,
            status_forcelist=[500, 502, 503, 504]
        )
        adapter = requests.adapters.HTTPAdapter(max_retries=retry_strategy)
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)

    def check_ollama_service(self):
        return check_ollama_service()

    def _encode_image(self, image_path: str) -> str:
        """ç¼–ç å›¾ç‰‡ï¼Œæ”¯æŒå‹ç¼©"""
        try:
            # éªŒè¯æ–‡ä»¶
            if not os.path.exists(image_path):
                raise ValueError("å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨")
                
            # éªŒè¯æ–‡ä»¶ç±»å‹
            try:
                with Image.open(image_path) as img:
                    if img.format.upper() not in {'JPEG', 'PNG', 'GIF', 'WEBP'}:
                        raise ValueError("ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼")
            except Exception as e:
                raise ValueError(f"æ— æ•ˆçš„å›¾ç‰‡æ–‡ä»¶: {str(e)}")
                
            # æ£€æŸ¥æ–‡ä»¶å¤§å°å¹¶åœ¨éœ€è¦æ—¶å‹ç¼©
            file_size = os.path.getsize(image_path)
            max_size = 10 * 1024 * 1024  # 10MB
            
            if file_size > max_size:
                compressed_path = self.resource_manager.create_temp_file(
                    suffix=os.path.splitext(image_path)[1]
                )
                image_path = self.compress_image(image_path, compressed_path, max_size)
            
            # ç¼–ç å›¾ç‰‡
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
                
        except Exception as e:
            logger.error(f"Image processing failed: {str(e)}")
            raise
            
    def compress_image(self, input_path: str, output_path: str, max_size: int) -> str:
        """å‹ç¼©å›¾ç‰‡åˆ°æŒ‡å®šå¤§å°ä»¥ä¸‹"""
        try:
            with Image.open(input_path) as img:
                format = img.format or 'JPEG'
                quality = 95
                
                while True:
                    # ä¿å­˜å‹ç¼©åçš„å›¾ç‰‡
                    img.save(output_path, format=format, quality=quality)
                    size = os.path.getsize(output_path)
                    
                    if size <= max_size or quality <= 5:
                        break
                        
                    quality -= 5
                    
                logger.info(f"Image compressed from {os.path.getsize(input_path)} to {size} bytes")
                return output_path
                
        except Exception as e:
            logger.error(f"Image compression failed: {str(e)}")
            if os.path.exists(output_path):
                self.resource_manager.remove_temp_file(output_path)
            raise

    @retry_on_exception(retries=Config.RETRY_ATTEMPTS)
    def _validate_input(self, text: str) -> str:
        """éªŒè¯å¹¶æ¸…ç†è¾“å…¥æ–‡æœ¬"""
        if not text or not text.strip():
            raise ValueError("è¾“å…¥ä¸èƒ½ä¸ºç©º")
        
        text = text.strip()
        if len(text) > Config.MAX_INPUT_LENGTH:
            raise ValueError(f"è¾“å…¥é•¿åº¦ä¸èƒ½è¶…è¿‡{Config.MAX_INPUT_LENGTH}å­—ç¬¦")
            
        # ç§»é™¤æ½œåœ¨çš„å±é™©å­—ç¬¦
        text = text.replace('<', '&lt;').replace('>', '&gt;')
        return text

    def get_model_list(self) -> Tuple[List[str], str]:
        """Returns (model_list, status_message)"""
        try:
            response = self.session.get(
                f"{Config.API_BASE_URL}/api/tags",
                timeout=Config.CHAT_TIMEOUT
            )
            response.raise_for_status()
            data = response.json()
            if not data or 'models' not in data or not data['models']:
                return [], "No models found. Please install at least one model using 'ollama pull model_name'"
            # Extract model names and check for vision capabilities
            models = []
            for model in data['models']:
                name = model['name']
                details = model.get('details', {})
                families = details.get('families', [])
                # Add a visual indicator for models with vision capabilities
                if 'clip' in families:
                    name = f"ğŸ–¼ï¸ {name}"
                models.append(name)
            return models, "Models refreshed successfully!"
        except requests.exceptions.ConnectionError:
            return [], "Error: Cannot connect to Ollama server. Is it running?"
        except requests.exceptions.Timeout:
            return [], "Error: Request timed out. Please try again."
        except Exception as e:
            logger.error(f"Error fetching model list: {e}")
            return [], f"Error: {str(e)}"

    def generate_response(self, prompt: str, model_name: str, image: Optional[str] = None, is_ocr: bool = False) -> str:
        """ç”Ÿæˆå“åº”ï¼Œæ”¯æŒOCRå’Œé—®ç­”ä¸¤ç§æ¨¡å¼"""
        # ç”Ÿæˆå”¯ä¸€çš„å¤„ç†ID
        process_id = f"{time.time()}_{model_name}"
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å¤„ç†æ­£åœ¨è¿›è¡Œ
            if self.process_state.is_processing(model_name):
                return "Error: æ¨¡å‹æ­£åœ¨å¤„ç†å…¶ä»–è¯·æ±‚ï¼Œè¯·ç¨åå†è¯•"
            
            # è®¾ç½®å¤„ç†çŠ¶æ€
            self.process_state.set_state(model_name, 'processing')
            
            # è¾“å…¥éªŒè¯
            try:
                prompt = self._validate_input(prompt)
                model_name = self._validate_input(model_name)
            except ValueError as e:
                return f"Error: {str(e)}"

            # è¯·æ±‚é¢‘ç‡é™åˆ¶
            if not self.rate_limit.is_allowed():
                return "Error: è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•"

            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"{prompt}_{model_name}_{image if image else ''}"
            cached_response = self.cache.get(cache_key)
            if cached_response:
                return cached_response

            # åŸæœ‰çš„å“åº”ç”Ÿæˆé€»è¾‘
            mode = "OCR" if is_ocr else "é—®ç­”"
            for attempt in range(Config.RETRY_ATTEMPTS):
                try:
                    # æ ¹æ®æ¨¡å¼é€‰æ‹©è¶…æ—¶æ—¶é—´
                    timeout = Config.OCR_TIMEOUT if is_ocr else Config.CHAT_TIMEOUT
                    
                    headers = {"Content-Type": "application/json"}
                    payload = {
                        "model": model_name.replace("ğŸ–¼ï¸ ", ""),
                        "prompt": prompt,
                        "stream": True
                    }
                    
                    if image:
                        payload["images"] = [image]
                    
                    response = self.session.post(
                        Config.API_GENERATE_URL,
                        headers=headers,
                        json=payload,
                        stream=True,
                        timeout=timeout
                    )
                    
                    if response.status_code != 200:
                        error_msg = f"æœåŠ¡å™¨è¿”å›é”™è¯¯ {response.status_code}"
                        try:
                            error_data = response.json()
                            if 'error' in error_data:
                                error_msg += f": {error_data['error']}"
                        except:
                            if response.text:
                                error_msg += f": {response.text}"
                        logger.error(f"{mode}è¯·æ±‚å¤±è´¥: {error_msg}")
                        return f"Error: {error_msg}"
                    
                    # Handle streaming response
                    full_response = []
                    try:
                        for line in response.iter_lines(decode_unicode=True):
                            if line:
                                try:
                                    data = json.loads(line)
                                    if 'response' in data:
                                        full_response.append(data['response'])
                                except json.JSONDecodeError as e:
                                    logger.warning(f"{mode}å“åº”è§£æé”™è¯¯: {str(e)}, line: {line}")
                                    continue
                    except requests.exceptions.ChunkedEncodingError as e:
                        error_msg = f"{mode}æµå¼å“åº”ä¸­æ–­: {str(e)}"
                        logger.error(error_msg)
                        if not full_response:
                            return f"Error: {error_msg}"
                        # å¦‚æœå·²ç»æœ‰éƒ¨åˆ†å“åº”ï¼Œç»§ç»­å¤„ç†
                        logger.warning(f"{mode}ä½¿ç”¨å·²æ¥æ”¶çš„éƒ¨åˆ†å“åº”")
                    
                    result = "".join(full_response).strip()
                    if not result:
                        error_msg = f"{mode}ç”Ÿæˆçš„å“åº”ä¸ºç©º"
                        logger.error(error_msg)
                        return f"Error: {error_msg}"
                    
                    # ç¼“å­˜ç»“æœ
                    self.cache.set(cache_key, result)
                    return result
                    
                except requests.exceptions.Timeout:
                    error_msg = f"{mode}è¯·æ±‚è¶…æ—¶(å°è¯• {attempt + 1}/{Config.RETRY_ATTEMPTS})"
                    logger.error(error_msg)
                    if attempt == Config.RETRY_ATTEMPTS - 1:
                        return f"Error: {error_msg}"
                    continue
                    
                except requests.exceptions.RequestException as e:
                    error_msg = f"{mode}è¯·æ±‚å¼‚å¸¸: {str(e)}"
                    logger.error(error_msg)
                    return f"Error: {error_msg}"
                    
                except Exception as e:
                    error_msg = f"{mode}å¤„ç†è¿‡ç¨‹å‡ºé”™: {str(e)}"
                    logger.error(error_msg)
                    return f"Error: {error_msg}"
                    
        finally:
            # æ¸…ç†å¤„ç†çŠ¶æ€
            self.process_state.clear_state(model_name)

    def clear_conversation(self) -> str:
        self.conversation.clear()
        return "Conversation cleared."

    def __del__(self):
        """æ¸…ç†èµ„æº"""
        try:
            self.session.close()
            if hasattr(self, 'resource_manager'):
                self.resource_manager.cleanup_all()
        except Exception as e:
            logger.error(f"Cleanup failed: {e}")

def check_ollama_service(max_attempts: int = 3, wait_time: int = 2) -> bool:
    """æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦å¯ç”¨ï¼Œæ”¯æŒå¤šæ¬¡é‡è¯•"""
    for attempt in range(max_attempts):
        try:
            response = requests.get(Config.API_BASE_URL, timeout=5)
            if response.status_code == 200:
                return True
            logger.warning(f"Ollama service check failed (attempt {attempt + 1}/{max_attempts}): Status code {response.status_code}")
        except requests.exceptions.ConnectionError:
            logger.warning(f"Ollama service connection failed (attempt {attempt + 1}/{max_attempts})")
        except requests.exceptions.Timeout:
            logger.warning(f"Ollama service timeout (attempt {attempt + 1}/{max_attempts})")
        except Exception as e:
            logger.error(f"Unexpected error checking Ollama service: {str(e)}")
            
        if attempt < max_attempts - 1:
            time.sleep(wait_time * (attempt + 1))  # æŒ‡æ•°é€€é¿
            
    return False

def create_interface() -> None:
    try:
        chatbot = ChatBot()
        
        # é¢„å…ˆè·å–æ¨¡å‹åˆ—è¡¨
        models, status = chatbot.get_model_list()
        if not models:
            logger.error(f"æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨: {status}")
            raise ValueError(f"æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨: {status}")
            
        # åˆ†ç¦»è§†è§‰æ¨¡å‹å’Œæ™®é€šæ¨¡å‹
        vision_models = [m for m in models if "ğŸ–¼ï¸" in m]
        all_models = models
        
        if not vision_models:
            logger.error("æœªæ‰¾åˆ°æ”¯æŒè§†è§‰åŠŸèƒ½çš„æ¨¡å‹")
            raise ValueError("æœªæ‰¾åˆ°æ”¯æŒè§†è§‰åŠŸèƒ½çš„æ¨¡å‹ï¼Œè¯·ç¡®ä¿å®‰è£…äº†æ”¯æŒè§†è§‰åŠŸèƒ½çš„æ¨¡å‹ï¼ˆå¦‚llavaï¼‰")
        
        interface = gr.Blocks(
            title="æ™ºèƒ½æ–‡æ¡£åˆ†æç³»ç»Ÿ",
            theme=gr.themes.Default(),
            css=".output-text {font-size: 16px;}"
        )

        with interface:
            # æ ‡é¢˜
            with gr.Column(elem_classes="header"):
                gr.Markdown("# æ™ºèƒ½æ–‡æ¡£åˆ†æç³»ç»Ÿ")
            
            # OCRåŒºåŸŸï¼ˆå¯é€‰ï¼‰
            with gr.Column():
                gr.Markdown("### å›¾ç‰‡è¯†åˆ«ï¼ˆå¯é€‰ï¼‰")
                with gr.Row():
                    image_input = gr.Image(
                        type="filepath",
                        label="ä¸Šä¼ å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰",
                        interactive=True
                    )
                    ocr_model_selector = gr.Dropdown(
                        choices=vision_models,
                        label="é€‰æ‹©OCRæ¨¡å‹ï¼ˆå¯é€‰ï¼‰",
                        value=None,
                        interactive=True
                    )
                ocr_output = gr.Textbox(
                    label="è¯†åˆ«ç»“æœ",
                    lines=4,
                    interactive=False,
                    elem_classes="output-text"
                )
            
            # é—®ç­”åŒºåŸŸ
            with gr.Column():
                gr.Markdown("### é—®ç­”")
                question_input = gr.Textbox(
                    label="è¾“å…¥é—®é¢˜",
                    lines=2,
                    interactive=True
                )
                with gr.Row():
                    chat_model_selector1 = gr.Dropdown(
                        choices=all_models,
                        label="æ¨¡å‹1",
                        value=all_models[0] if all_models else None,
                        interactive=True
                    )
                    chat_model_selector2 = gr.Dropdown(
                        choices=all_models,
                        label="æ¨¡å‹2ï¼ˆå¯é€‰ï¼‰",
                        value=None,
                        interactive=True
                    )
                    chat_model_selector3 = gr.Dropdown(
                        choices=all_models,
                        label="æ¨¡å‹3ï¼ˆå¯é€‰ï¼‰",
                        value=None,
                        interactive=True
                    )
                with gr.Row():
                    chat_output1 = gr.Textbox(
                        label="æ¨¡å‹1å›ç­”",
                        lines=4,
                        interactive=False,
                        elem_classes="output-text"
                    )
                    chat_output2 = gr.Textbox(
                        label="æ¨¡å‹2å›ç­”",
                        lines=4,
                        interactive=False,
                        elem_classes="output-text"
                    )
                    chat_output3 = gr.Textbox(
                        label="æ¨¡å‹3å›ç­”",
                        lines=4,
                        interactive=False,
                        elem_classes="output-text"
                    )
            
            # çŠ¶æ€æ˜¾ç¤º
            status_text = gr.Textbox(
                label="çŠ¶æ€",
                interactive=False,
                elem_classes="status-text"
            )
            
            # å¤„ç†æŒ‰é’®
            with gr.Row():
                process_button = gr.Button(
                    "å¼€å§‹å¤„ç†",
                    variant="primary",
                    elem_classes="primary",
                    interactive=True
                )
                retry_button = gr.Button(
                    "é‡æ–°é—®ç­”",
                    variant="secondary",
                    elem_classes="secondary",
                    interactive=True
                )

            # å­˜å‚¨OCRç»“æœç”¨äºé‡è¯•
            ocr_result_store = gr.State(value=None)

            # å¤„ç†å‡½æ•°ï¼šä¸€é”®å¤„ç†æ‰€æœ‰æµç¨‹
            def process_all(image_path, ocr_model, question, chat_model1, chat_model2, chat_model3, progress=gr.Progress()):
                """ä¸€é”®å¤„ç†æ‰€æœ‰æµç¨‹"""
                # åŸºæœ¬éªŒè¯
                if not question.strip():
                    return (
                        "",
                        "",
                        "",
                        "",
                        "è¯·è¾“å…¥é—®é¢˜",
                        None
                    )

                if not any([chat_model1, chat_model2, chat_model3]):
                    return (
                        "",
                        "",
                        "",
                        "",
                        "è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªé—®ç­”æ¨¡å‹",
                        None
                    )

                results = {
                    "ocr_output": "",
                    "chat_output1": "",
                    "chat_output2": "",
                    "chat_output3": "",
                    "status_text": "å¤„ç†ä¸­...",
                    "ocr_result_store": None
                }

                try:
                    chatbot = ChatBot()
                    qa_prompt = question
                    
                    # OCRå¤„ç†ï¼ˆå®Œå…¨å¯é€‰ï¼‰
                    if image_path and ocr_model:
                        try:
                            progress(0.2, desc="æ­£åœ¨è¿›è¡Œå›¾ç‰‡è¯†åˆ«...")
                            base64_image = chatbot._encode_image(image_path)
                            ocr_prompt = "è¯·è¯†åˆ«è¿™å¼ å›¾ç‰‡ä¸­çš„æ–‡å­—å†…å®¹ï¼Œå°½å¯èƒ½ä¿æŒåŸæœ‰æ ¼å¼ã€‚"
                            ocr_result = chatbot.generate_response(ocr_prompt, ocr_model, base64_image, is_ocr=True)
                            
                            # æ¸…ç†OCRç»“æœæ ¼å¼
                            if ocr_result and not ocr_result.startswith("Error:"):
                                # ç§»é™¤å¤šä½™çš„ç©ºè¡Œ,ä¿ç•™æ®µè½æ ¼å¼
                                ocr_result = "\n".join(line for line in ocr_result.splitlines() if line.strip())
                                results["ocr_output"] = ocr_result
                                results["ocr_result_store"] = ocr_result
                                # å°†OCRç»“æœä½œä¸ºè¡¥å……ä¿¡æ¯æ·»åŠ åˆ°é—®é¢˜ä¸­
                                qa_prompt = f"{question}\n\nè¡¥å……ä¿¡æ¯ï¼š\n{ocr_result}"
                            else:
                                # OCRå¤±è´¥,è®°å½•é”™è¯¯ä½†ç»§ç»­é—®ç­”
                                logger.error(f"OCRè¯†åˆ«å¤±è´¥: {ocr_result}")
                                results["ocr_output"] = ocr_result
                                results["ocr_result_store"] = None
                                qa_prompt = question
                        except Exception as e:
                            error_msg = f"OCRå¤„ç†å‡ºé”™: {str(e)}"
                            logger.error(error_msg)
                            results["ocr_output"] = f"é”™è¯¯: {error_msg}"
                            results["ocr_result_store"] = None
                            # OCRé”™è¯¯ä¸å½±å“é—®ç­”ç»§ç»­è¿›è¡Œ
                            qa_prompt = question
                    
                    # é—®ç­”å¤„ç†
                    progress(0.4, desc="å‡†å¤‡è¿›è¡Œé—®ç­”...")
                    total_models = sum(1 for m in [chat_model1, chat_model2, chat_model3] if m)
                    current_model = 0
                    
                    if chat_model1:
                        current_model += 1
                        progress(0.4 + 0.6 * (current_model / total_models), desc=f"è·å–æ¨¡å‹{current_model}å›ç­”...")
                        try:
                            results["chat_output1"] = chatbot.generate_response(qa_prompt, chat_model1)
                        except Exception as e:
                            logger.error(f"æ¨¡å‹1å›ç­”å‡ºé”™: {str(e)}")
                            results["chat_output1"] = f"é”™è¯¯: {str(e)}"
                    
                    if chat_model2:
                        current_model += 1
                        progress(0.4 + 0.6 * (current_model / total_models), desc=f"è·å–æ¨¡å‹{current_model}å›ç­”...")
                        try:
                            results["chat_output2"] = chatbot.generate_response(qa_prompt, chat_model2)
                        except Exception as e:
                            logger.error(f"æ¨¡å‹2å›ç­”å‡ºé”™: {str(e)}")
                            results["chat_output2"] = f"é”™è¯¯: {str(e)}"
                    
                    if chat_model3:
                        current_model += 1
                        progress(0.4 + 0.6 * (current_model / total_models), desc=f"è·å–æ¨¡å‹{current_model}å›ç­”...")
                        try:
                            results["chat_output3"] = chatbot.generate_response(qa_prompt, chat_model3)
                        except Exception as e:
                            logger.error(f"æ¨¡å‹3å›ç­”å‡ºé”™: {str(e)}")
                            results["chat_output3"] = f"é”™è¯¯: {str(e)}"
                    
                    progress(1.0, desc="å¤„ç†å®Œæˆ")
                    results["status_text"] = "å¤„ç†å®Œæˆ"
                    return (
                        results["ocr_output"],
                        results["chat_output1"],
                        results["chat_output2"],
                        results["chat_output3"],
                        results["status_text"],
                        results["ocr_result_store"]
                    )
                    
                except Exception as e:
                    logger.error(f"å¤„ç†è¿‡ç¨‹å‡ºé”™: {str(e)}")
                    error_msg = f"é”™è¯¯: {str(e)}"
                    return (
                        "",
                        "",
                        "",
                        "",
                        error_msg,
                        None
                    )

            # é‡è¯•é—®ç­”å‡½æ•°
            def retry_qa(question, chat_model1, chat_model2, chat_model3, ocr_result):
                """é‡æ–°è¿›è¡Œé—®ç­”"""
                if not question.strip():
                    return ["è¯·è¾“å…¥é—®é¢˜"] * 3

                if not any([chat_model1, chat_model2, chat_model3]):
                    return ["è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªé—®ç­”æ¨¡å‹"] * 3

                try:
                    chatbot = ChatBot()
                    # æ„å»ºæç¤ºè¯ï¼šå¦‚æœæœ‰OCRç»“æœå°±ä½œä¸ºè¡¥å……ä¿¡æ¯
                    qa_prompt = question
                    if ocr_result and ocr_result.strip():
                        qa_prompt = f"{question}\n\nè¡¥å……ä¿¡æ¯ï¼š\n{ocr_result}"
                    
                    results = [""] * 3
                    if chat_model1:
                        try:
                            results[0] = chatbot.generate_response(qa_prompt, chat_model1)
                        except Exception as e:
                            logger.error(f"æ¨¡å‹1é‡è¯•å‡ºé”™: {str(e)}")
                            results[0] = f"é”™è¯¯: {str(e)}"
                    
                    if chat_model2:
                        try:
                            results[1] = chatbot.generate_response(qa_prompt, chat_model2)
                        except Exception as e:
                            logger.error(f"æ¨¡å‹2é‡è¯•å‡ºé”™: {str(e)}")
                            results[1] = f"é”™è¯¯: {str(e)}"
                    
                    if chat_model3:
                        try:
                            results[2] = chatbot.generate_response(qa_prompt, chat_model3)
                        except Exception as e:
                            logger.error(f"æ¨¡å‹3é‡è¯•å‡ºé”™: {str(e)}")
                            results[2] = f"é”™è¯¯: {str(e)}"
                    
                    return results
                except Exception as e:
                    logger.error(f"é‡è¯•è¿‡ç¨‹å‡ºé”™: {str(e)}")
                    return [f"é”™è¯¯: {str(e)}"] * 3

            # å¤„ç†æŒ‰é’®ç‚¹å‡»äº‹ä»¶
            process_button.click(
                fn=process_all,
                inputs=[
                    image_input,
                    ocr_model_selector,
                    question_input,
                    chat_model_selector1,
                    chat_model_selector2,
                    chat_model_selector3
                ],
                outputs=[
                    ocr_output,
                    chat_output1,
                    chat_output2,
                    chat_output3,
                    status_text,
                    ocr_result_store
                ],
                api_name="process"
            )

            # é‡è¯•æŒ‰é’®ç‚¹å‡»äº‹ä»¶
            retry_button.click(
                fn=retry_qa,
                inputs=[
                    question_input,
                    chat_model_selector1,
                    chat_model_selector2,
                    chat_model_selector3,
                    ocr_result_store
                ],
                outputs=[
                    chat_output1,
                    chat_output2,
                    chat_output3
                ],
                api_name="retry"
            )

            # å›¾ç‰‡å’Œæ¨¡å‹é€‰æ‹©å˜æ›´äº‹ä»¶
            def clear_outputs():
                return [""] * 4  # æ¸…ç©º4ä¸ªè¾“å‡ºæ¡†
                
            image_input.change(
                fn=clear_outputs,
                inputs=None,
                outputs=[ocr_output, chat_output1, chat_output2, chat_output3]
            )
            
            ocr_model_selector.change(
                fn=clear_outputs,
                inputs=None,
                outputs=[ocr_output, chat_output1, chat_output2, chat_output3]
            )

        interface.launch(
            server_name="0.0.0.0",
            server_port=7588,
            share=False,
            inbrowser=True
        )
        
    except Exception as e:
        logger.error(f"Failed to create interface: {e}")
        sys.exit(1)

if __name__ == "__main__":
    # è®¾ç½®æ—¥å¿—è¾“å‡ºåˆ°æ–‡ä»¶
    log_file = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'chatbot.log')
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
    logger.addHandler(file_handler)
    
    try:
        logger.info("Starting chatbot interface...")
        print("æ­£åœ¨å¯åŠ¨èŠå¤©æœºå™¨äººç•Œé¢...")
        if not ChatBot().check_ollama_service():
            error_msg = "Error: Ollama service is not running. Please start Ollama first."
            logger.error(error_msg)
            print(error_msg)
            input("æŒ‰å›è½¦é”®é€€å‡º...")
            sys.exit(1)
            
        create_interface()  # ç›´æ¥è°ƒç”¨create_interfaceï¼Œå®ƒå·²ç»åŒ…å«äº†launché€»è¾‘
    except Exception as e:
        print(f"\nError: {str(e)}")
        logger.error(f"Application error: {str(e)}", exc_info=True)
        print("\nPress Enter to exit...")
        input()
        sys.exit(1)
